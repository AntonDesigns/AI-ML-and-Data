{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138f4e6b",
   "metadata": {},
   "source": [
    "TMDB Movie Data Collector for Movie Success Prediction\n",
    "\n",
    "This notebook creates a CSV dataset from TMDB API for data provisioning analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90662335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "API_KEY = \"064388427da12053da4c13de808686df\"  \n",
    "BASE_URL = \"https://api.themoviedb.org/3\"\n",
    "API_KEY_OMDB = \"1f805bfb\"\n",
    "REQUEST_DELAY = 0.25  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f989f0",
   "metadata": {},
   "source": [
    "api\n",
    "Handler\n",
    "\n",
    "Manages communication with multiple APIs (TMDB + OMDb) for richer dataset collection.\n",
    "\n",
    "I added OMDb integration because TMDB lacks IMDb ratings and Rotten Tomatoes scores,\n",
    "\n",
    "which are crucial validation metrics for movie success prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877b88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class APIHandler:\n",
    "    def __init__(self, tmdb_key, omdb_key=None):\n",
    "        self.tmdb_key = tmdb_key\n",
    "        self.omdb_key = omdb_key\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "    def get_tmdb_data(self, endpoint, params=None):\n",
    "        if params is None:\n",
    "            params = {}\n",
    "        params['api_key'] = self.tmdb_key\n",
    "        \n",
    "        url = f\"https://api.themoviedb.org/3/{endpoint}\"\n",
    "        \n",
    "        try:\n",
    "            time.sleep(0.25)  \n",
    "            response = self.session.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"TMDB request failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_omdb_data(self, title, year):\n",
    "        if not self.omdb_key:\n",
    "            return {}\n",
    "            \n",
    "        try:\n",
    "            params = {\n",
    "                'apikey': self.omdb_key,\n",
    "                't': title,\n",
    "                'y': year\n",
    "            }\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "            response = self.session.get(\"http://www.omdbapi.com/\", params=params)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if data.get('Response') == 'True':\n",
    "                    return {\n",
    "                        'imdb_rating': self._to_float(data.get('imdbRating')),\n",
    "                        'imdb_votes': self._parse_votes(data.get('imdbVotes')),\n",
    "                        'rotten_tomatoes_score': self._get_rt_score(data.get('Ratings', [])),\n",
    "                        'metacritic_score': self._to_int(data.get('Metascore')),\n",
    "                        'awards': data.get('Awards'),\n",
    "                        'writer': data.get('Writer'),\n",
    "                        'rated': data.get('Rated'),\n",
    "                        'country': data.get('Country')\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            print(f\"OMDb request failed for {title}: {e}\")\n",
    "        \n",
    "        return {}\n",
    "    \n",
    "    def _to_float(self, value):\n",
    "        if value and value != 'N/A':\n",
    "            try:\n",
    "                return float(value)\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "    \n",
    "    def _to_int(self, value):\n",
    "        if value and value != 'N/A':\n",
    "            try:\n",
    "                return int(value)\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "    \n",
    "    def _parse_votes(self, votes_str):\n",
    "        if votes_str and votes_str != 'N/A':\n",
    "            try:\n",
    "                return int(votes_str.replace(',', ''))\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "    \n",
    "    def _get_rt_score(self, ratings_list):\n",
    "        for rating in ratings_list:\n",
    "            if rating.get('Source') == 'Rotten Tomatoes':\n",
    "                score_str = rating.get('Value', '')\n",
    "                if '%' in score_str:\n",
    "                    try:\n",
    "                        return int(score_str.replace('%', ''))\n",
    "                    except:\n",
    "                        pass\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5d2e5",
   "metadata": {},
   "source": [
    "Movie Discovery Engine\n",
    "\n",
    "This class discovers movies using TMDB's filtering system to find movies suitable for success prediction\n",
    "\n",
    "I'm filtering for movies with revenue data since that's essential for creating our target variable (Hit/Break-even/Flop)\n",
    "\n",
    "I will ffocus on modern movies (1990+) because older movies have different market dynamics\n",
    "\n",
    "This systematic discovery ensures we get a representative sample for training our prediction model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77658cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDiscovery:\n",
    "    def __init__(self, api_handler):\n",
    "        self.api = api_handler\n",
    "        \n",
    "    def discover_movies(self, pages=100, start_page=1):  \n",
    "        print(f\"Discovering movies from pages {start_page} to {start_page + pages - 1}...\")\n",
    "        discovered_movies = []\n",
    "        \n",
    "        for page in range(start_page, start_page + pages):  \n",
    "            params = {\n",
    "                'page': page,\n",
    "                'sort_by': 'popularity.desc',\n",
    "                'include_adult': 'false',\n",
    "                'with_revenue.gte': 1,\n",
    "                'primary_release_date.gte': '1990-01-01',\n",
    "                'primary_release_date.lte': '2024-12-31'\n",
    "            }\n",
    "            \n",
    "            data = self.api.get_tmdb_data('discover/movie', params)\n",
    "            if data and 'results' in data:\n",
    "                discovered_movies.extend(data['results'])\n",
    "                print(f\"Page {page}: Found {len(data['results'])} movies\")\n",
    "            else:\n",
    "                print(f\"Failed to get data for page {page}\")\n",
    "                \n",
    "        print(f\"Total discovered movies: {len(discovered_movies)}\")\n",
    "        return discovered_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd907c",
   "metadata": {},
   "source": [
    "Movie Details Extractor\n",
    "\n",
    "This class extracts comprehensive financial and content details for each movie\n",
    "\n",
    "Budget and revenue are critical for creating my success classification target variable\n",
    "\n",
    "Genre, runtime, release date affect audience appeal and box office performance\n",
    "\n",
    "These features form the core predictive variables for my ML model\n",
    "\n",
    "Combines TMDB base data with OMDb enrichment for comprehensive movie profiles.\n",
    "\n",
    "I expanded this to include external data validation because relying on a single source\n",
    "can lead to biased or incomplete information that affects model accuracy.\n",
    "\n",
    "The integration provides cross-validation between data sources and captures\n",
    "different perspectives on movie quality (audience vs professional critics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61091d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDetailsExtractor:\n",
    "    def __init__(self, api_handler):\n",
    "        self.api = api_handler\n",
    "        \n",
    "    def get_movie_details(self, movie_id, title=None, year=None, include_omdb=True):\n",
    "        \"\"\"Get complete movie information\"\"\"\n",
    "        details = self.api.get_tmdb_data(f'movie/{movie_id}')\n",
    "        if not details:\n",
    "            return None\n",
    "            \n",
    "        movie_data = {\n",
    "            'id': details.get('id'),\n",
    "            'title': details.get('title'),\n",
    "            'budget': details.get('budget', 0),\n",
    "            'revenue': details.get('revenue', 0),\n",
    "            'runtime': details.get('runtime'),\n",
    "            'release_date': details.get('release_date'),\n",
    "            'vote_average': details.get('vote_average'),\n",
    "            'vote_count': details.get('vote_count'),\n",
    "            'popularity': details.get('popularity'),\n",
    "            'overview': details.get('overview'),\n",
    "            'original_language': details.get('original_language'),\n",
    "            'adult': details.get('adult')\n",
    "        }\n",
    "        \n",
    "        if details.get('genres'):\n",
    "            movie_data['genres'] = [g['name'] for g in details['genres']]\n",
    "            movie_data['primary_genre'] = details['genres'][0]['name']\n",
    "            movie_data['genre_count'] = len(details['genres'])\n",
    "        else:\n",
    "            movie_data['genres'] = []\n",
    "            movie_data['primary_genre'] = None\n",
    "            movie_data['genre_count'] = 0\n",
    "            \n",
    "        if details.get('production_companies'):\n",
    "            movie_data['production_companies'] = [pc['name'] for pc in details['production_companies']]\n",
    "            movie_data['main_production_company'] = details['production_companies'][0]['name']\n",
    "            movie_data['production_company_count'] = len(details['production_companies'])\n",
    "        else:\n",
    "            movie_data['production_companies'] = []\n",
    "            movie_data['main_production_company'] = None\n",
    "            movie_data['production_company_count'] = 0\n",
    "        \n",
    "        if details.get('production_countries'):\n",
    "            movie_data['production_countries'] = [pc['name'] for pc in details['production_countries']]\n",
    "            movie_data['main_production_country'] = details['production_countries'][0]['name']\n",
    "            movie_data['is_us_movie'] = any('United States' in pc['name'] for pc in details['production_countries'])\n",
    "        else:\n",
    "            movie_data['production_countries'] = []\n",
    "            movie_data['main_production_country'] = None\n",
    "            movie_data['is_us_movie'] = False\n",
    "        \n",
    "        if include_omdb and title and year:\n",
    "            omdb_data = self.api.get_omdb_data(title, year)\n",
    "            movie_data.update(omdb_data)\n",
    "        \n",
    "        return movie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c5b40",
   "metadata": {},
   "source": [
    "Credits and Cast Extractor\n",
    "\n",
    "This class extracts director and cast information which are strong predictors of movie success\n",
    "\n",
    "Director track record (previous hit rate) is one of the most reliable success predictors in the industry\n",
    "\n",
    "Lead actor popularity and star power significantly influence opening weekend box office\n",
    "\n",
    "Top-billed cast affects marketing appeal and audience draw\n",
    "\n",
    "This data enables my model to factor in human talent as a success variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditsExtractor:\n",
    "    def __init__(self, api_handler):\n",
    "        self.api = api_handler\n",
    "        \n",
    "    def get_movie_credits(self, movie_id):\n",
    "        credits = self.api.get_tmdb_data(f'movie/{movie_id}/credits')\n",
    "        if not credits:\n",
    "            return {}\n",
    "            \n",
    "        credit_data = {}\n",
    "        \n",
    "        if credits.get('crew'):\n",
    "            directors = [person for person in credits['crew'] if person['job'] == 'Director']\n",
    "            if directors:\n",
    "                credit_data['director'] = directors[0]['name']\n",
    "                credit_data['director_id'] = directors[0]['id']\n",
    "            else:\n",
    "                credit_data['director'] = None\n",
    "                credit_data['director_id'] = None\n",
    "        \n",
    "        if credits.get('cast'):\n",
    "            main_cast = credits['cast'][:5]\n",
    "            credit_data['main_cast'] = [actor['name'] for actor in main_cast]\n",
    "            credit_data['main_cast_ids'] = [actor['id'] for actor in main_cast]\n",
    "            credit_data['lead_actor'] = main_cast[0]['name'] if main_cast else None\n",
    "            credit_data['lead_actor_id'] = main_cast[0]['id'] if main_cast else None\n",
    "        else:\n",
    "            credit_data['main_cast'] = []\n",
    "            credit_data['main_cast_ids'] = []\n",
    "            credit_data['lead_actor'] = None\n",
    "            credit_data['lead_actor_id'] = None\n",
    "            \n",
    "        return credit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6967b9",
   "metadata": {},
   "source": [
    "Success Classification Creator\n",
    "\n",
    "This class creates the target variable for my machine learning model using industry-standard profitability ratios\n",
    "\n",
    "Movies need 2.5x revenue vs budget to be truly profitable after marketing and distribution costs\n",
    "\n",
    "This classification system (Hit/Break-even/Flop) matches real Hollywood investment decision-making\n",
    "\n",
    "Creating accurate target labels is essential for supervised learning and model evaluation\n",
    "\n",
    "I expanded this to leverage external data for more sophisticated feature engineering\n",
    "that captures market dynamics and audience-critic divides.\n",
    "\n",
    "The rating comparison features help identify movies that perform differently\n",
    "with critics versus general audiences, which affects long-term commercial success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49cf42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuccessClassifier:\n",
    "    def classify_movie_success(self, revenue, budget):\n",
    "        if budget == 0 or revenue == 0:\n",
    "            return None\n",
    "            \n",
    "        profit_ratio = revenue / budget\n",
    "        \n",
    "        if profit_ratio < 1.0:\n",
    "            return \"Flop\"\n",
    "        elif profit_ratio < 2.5:\n",
    "            return \"Break-even\" \n",
    "        else:\n",
    "            return \"Hit\"\n",
    "    \n",
    "    def add_useful_features(self, movie_data):\n",
    "        \n",
    "        if movie_data.get('release_date'):\n",
    "            try:\n",
    "                date_obj = datetime.strptime(movie_data['release_date'], '%Y-%m-%d')\n",
    "                movie_data['release_year'] = date_obj.year\n",
    "                movie_data['release_month'] = date_obj.month\n",
    "                movie_data['release_quarter'] = (date_obj.month - 1) // 3 + 1\n",
    "                movie_data['is_summer_movie'] = date_obj.month in [5, 6, 7, 8]  \n",
    "                movie_data['is_holiday_movie'] = date_obj.month in [11, 12]    \n",
    "            except:\n",
    "                movie_data['release_year'] = None\n",
    "                movie_data['release_month'] = None\n",
    "                movie_data['release_quarter'] = None\n",
    "                movie_data['is_summer_movie'] = None\n",
    "                movie_data['is_holiday_movie'] = None\n",
    "        \n",
    "        movie_data['success_category'] = self.classify_movie_success(\n",
    "            movie_data.get('revenue', 0), \n",
    "            movie_data.get('budget', 0)\n",
    "        )\n",
    "        \n",
    "        if movie_data.get('budget', 0) > 0:\n",
    "            movie_data['profit_ratio'] = movie_data.get('revenue', 0) / movie_data['budget']\n",
    "        else:\n",
    "            movie_data['profit_ratio'] = None\n",
    "\n",
    "        if movie_data.get('imdb_rating') and movie_data.get('vote_average'):\n",
    "            movie_data['imdb_vs_tmdb_difference'] = movie_data['imdb_rating'] - movie_data['vote_average']\n",
    "            movie_data['ratings_agree'] = abs(movie_data['imdb_vs_tmdb_difference']) < 0.5\n",
    "        \n",
    "        movie_data['has_awards'] = self._check_for_awards(movie_data.get('awards'))\n",
    "        movie_data['has_oscar_mention'] = self._check_for_oscars(movie_data.get('awards'))\n",
    "        \n",
    "        movie_data['is_r_rated'] = movie_data.get('rated') == 'R'\n",
    "        movie_data['is_family_friendly'] = movie_data.get('rated') in ['G', 'PG', 'PG-13']\n",
    "        \n",
    "        budget = movie_data.get('budget', 0)\n",
    "        if budget >= 100_000_000:\n",
    "            movie_data['budget_category'] = 'Blockbuster'\n",
    "        elif budget >= 50_000_000:\n",
    "            movie_data['budget_category'] = 'Major Studio'\n",
    "        elif budget >= 15_000_000:\n",
    "            movie_data['budget_category'] = 'Mid-Budget'\n",
    "        elif budget > 0:\n",
    "            movie_data['budget_category'] = 'Independent'\n",
    "        else:\n",
    "            movie_data['budget_category'] = 'Unknown'\n",
    "        \n",
    "        runtime = movie_data.get('runtime')\n",
    "        if runtime:\n",
    "            if runtime < 90:\n",
    "                movie_data['runtime_category'] = 'Short'\n",
    "            elif runtime <= 120:\n",
    "                movie_data['runtime_category'] = 'Standard'\n",
    "            else:\n",
    "                movie_data['runtime_category'] = 'Long'\n",
    "        else:\n",
    "            movie_data['runtime_category'] = 'Unknown'\n",
    "            \n",
    "        return movie_data\n",
    "    \n",
    "    def _check_for_awards(self, awards_str):\n",
    "        if not awards_str or awards_str == 'N/A':\n",
    "            return False\n",
    "        \n",
    "        major_awards = ['Oscar', 'Golden Globe', 'BAFTA', 'Emmy', 'SAG Award']\n",
    "        return any(award in awards_str for award in major_awards)\n",
    "    \n",
    "    def _check_for_oscars(self, awards_str):\n",
    "        if not awards_str or awards_str == 'N/A':\n",
    "            return False\n",
    "        return 'Oscar' in awards_str or 'Academy Award' in awards_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01f15eb",
   "metadata": {},
   "source": [
    "Data Quality Controller\n",
    "\n",
    "This class ensures collected data meets quality standards for machine learning\n",
    "\n",
    "Movies without budget or revenue data cannot be used for success prediction training\n",
    "\n",
    "Filtering out incomplete records prevents model training on unreliable data\n",
    "\n",
    "Quality control at collection stage reduces data preparation work later\n",
    "\n",
    "I expanded this to handle validation across multiple APIs and create completeness metrics\n",
    "that help identify the most reliable records for model training.\n",
    "\n",
    "The completeness scoring helps weight predictions by data quality and identifies\n",
    "records that might need additional validation or exclusion from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ad9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQualityChecker:\n",
    "    def is_good_movie_data(self, movie_data):\n",
    "        required_fields = ['budget', 'revenue', 'title', 'release_date']\n",
    "        \n",
    "        for field in required_fields:\n",
    "            if not movie_data.get(field):\n",
    "                return False\n",
    "                \n",
    "        if movie_data.get('budget', 0) <= 0:\n",
    "            return False\n",
    "            \n",
    "        if movie_data.get('revenue', 0) <= 0:\n",
    "            return False\n",
    "        \n",
    "        runtime = movie_data.get('runtime')\n",
    "        if runtime and (runtime < 60 or runtime > 300):\n",
    "            print(f\"Warning: Weird runtime {runtime} for {movie_data.get('title')}\")\n",
    "            \n",
    "        tmdb_rating = movie_data.get('vote_average')\n",
    "        if tmdb_rating and (tmdb_rating < 0 or tmdb_rating > 10):\n",
    "            print(f\"Warning: Bad TMDB rating {tmdb_rating} for {movie_data.get('title')}\")\n",
    "            return False\n",
    "            \n",
    "        imdb_rating = movie_data.get('imdb_rating')\n",
    "        if imdb_rating and (imdb_rating < 0 or imdb_rating > 10):\n",
    "            print(f\"Warning: Bad IMDb rating {imdb_rating} for {movie_data.get('title')}\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def calculate_data_completeness(self, movie_data):\n",
    "        core_fields = ['budget', 'revenue', 'title', 'release_date', 'runtime', 'vote_average']\n",
    "        extra_fields = ['imdb_rating', 'rotten_tomatoes_score', 'awards', 'director', 'lead_actor']\n",
    "        \n",
    "        core_complete = sum(1 for field in core_fields if movie_data.get(field) is not None)\n",
    "        extra_complete = sum(1 for field in extra_fields if movie_data.get(field) is not None)\n",
    "        \n",
    "        core_score = core_complete / len(core_fields)\n",
    "        extra_score = extra_complete / len(extra_fields)\n",
    "        \n",
    "        overall_score = (core_score * 0.7) + (extra_score * 0.3)\n",
    "        \n",
    "        return {\n",
    "            'core_completeness': core_score,\n",
    "            'extra_completeness': extra_score,\n",
    "            'overall_completeness': overall_score\n",
    "        }\n",
    "    \n",
    "    def clean_movie_data(self, movie_data):\n",
    "        if isinstance(movie_data.get('genres'), list):\n",
    "            movie_data['genres_count'] = len(movie_data['genres'])\n",
    "        else:\n",
    "            movie_data['genres_count'] = 0\n",
    "            \n",
    "        if isinstance(movie_data.get('main_cast'), list):\n",
    "            movie_data['cast_count'] = len(movie_data['main_cast'])\n",
    "        else:\n",
    "            movie_data['cast_count'] = 0\n",
    "\n",
    "        text_fields = ['title', 'overview']\n",
    "        for field in text_fields:\n",
    "            if movie_data.get(field):\n",
    "                movie_data[field] = movie_data[field].strip()\n",
    "        \n",
    "        completeness = self.calculate_data_completeness(movie_data)\n",
    "        movie_data.update(completeness)\n",
    "        \n",
    "        return movie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4373246a",
   "metadata": {},
   "source": [
    "\n",
    "CSV Dataset Exporter\n",
    "\n",
    "This class saves the collected movie data to CSV format for the data provisioning phase\n",
    "\n",
    "Proper file naming with timestamps enables version control and reproducible research\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45960c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVExporter:\n",
    "    def save_to_csv(self, movies_data, filename=None):\n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"movie_dataset_{timestamp}.csv\"\n",
    "        \n",
    "        df = pd.DataFrame(movies_data)\n",
    "        \n",
    "        list_columns = ['genres', 'production_companies', 'main_cast', 'main_cast_ids']\n",
    "        for col in list_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else x)\n",
    "        \n",
    "        df.to_csv(filename, index=False)\n",
    "        \n",
    "        print(f\"Dataset saved to: {filename}\")\n",
    "        print(f\"Total movies: {len(df)}\")\n",
    "        print(f\"Total columns: {len(df.columns)}\")\n",
    "        \n",
    "        return filename, df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4297ed2",
   "metadata": {},
   "source": [
    "Data Integration Techniques (Applied from Croatia GDP exercise)\n",
    " **Why I Added Data Integration and Versioning Classes**\n",
    "\n",
    "**Why Data Integration is Critical for Movie Success Prediction:**\n",
    "\n",
    "Single data sources have limitations - TMDB lacks critical validation metrics like IMDb ratings\n",
    "\n",
    "and professional critic scores that significantly impact movie success patterns.\n",
    "\n",
    "The Croatia GDP exercise taught me that combining multiple reliable data sources creates\n",
    "\n",
    "richer datasets that improve model accuracy and provide cross-validation.\n",
    "\n",
    " **Business Need:** \n",
    "Movie studios make million-dollar decisions based on these models.\n",
    "\n",
    "Missing external validation signals leads to poor investment choices.\n",
    "\n",
    "\n",
    " **Why These Specific Integration Techniques:**\n",
    " - Union: Combine data from multiple collection runs as dataset grows\n",
    " - Inner Join: Create high-quality training sets with complete external validation\n",
    " - Left Join: Preserve all movies while adding external data where available\n",
    " - Full Outer Join: Analyze different movie eras with varying data availability\n",
    " - Exclusion: Remove anomalous periods (like pandemic) that would skew predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6738a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataIntegrator:\n",
    "    def __init__(self):\n",
    "        self.integration_log = []\n",
    "    \n",
    "    def log_integration(self, technique, description, result_shape):\n",
    "        self.integration_log.append({\n",
    "            'technique': technique,\n",
    "            'description': description,\n",
    "            'result_shape': result_shape,\n",
    "            'timestamp': datetime.now()\n",
    "        })\n",
    "    \n",
    "    def union_integration(self, tmdb_data_batch1, tmdb_data_batch2):\n",
    "        print(\"=== UNION INTEGRATION ===\")\n",
    "        \n",
    "        combined = pd.concat([tmdb_data_batch1, tmdb_data_batch2], ignore_index=True)\n",
    "        combined = combined.drop_duplicates(subset=['id'])\n",
    "        \n",
    "        print(f\"Batch 1: {len(tmdb_data_batch1)} movies\")\n",
    "        print(f\"Batch 2: {len(tmdb_data_batch2)} movies\")\n",
    "        print(f\"Union result: {len(combined)} movies\")\n",
    "        \n",
    "        self.log_integration(\"Union\", \"Combined TMDB collection batches\", combined.shape)\n",
    "        return combined\n",
    "    \n",
    "    def inner_join_integration(self, tmdb_data, omdb_enhanced_data):\n",
    "        print(\"=== INNER JOIN INTEGRATION ===\")\n",
    "        \n",
    "        omdb_cols = ['id']\n",
    "        available_omdb = []\n",
    "        for col in ['imdb_rating', 'rotten_tomatoes_score', 'awards']:\n",
    "            if col in omdb_enhanced_data.columns:\n",
    "                omdb_cols.append(col)\n",
    "                available_omdb.append(col)\n",
    "        \n",
    "        if len(available_omdb) > 0:\n",
    "            has_omdb_data = omdb_enhanced_data[available_omdb[0]].notna()\n",
    "            omdb_movies = omdb_enhanced_data[has_omdb_data].copy()\n",
    "            inner_joined = pd.merge(tmdb_data, omdb_movies[omdb_cols], on='id', how='inner')\n",
    "        else:\n",
    "            inner_joined = pd.merge(tmdb_data, omdb_enhanced_data[['id']], on='id', how='inner')\n",
    "        \n",
    "        print(f\"TMDB data: {len(tmdb_data)} movies\")\n",
    "        print(f\"Movies with OMDb data: {len(omdb_enhanced_data)} movies\")\n",
    "        print(f\"Inner join result: {len(inner_joined)} movies\")\n",
    "        \n",
    "        self.log_integration(\"Inner Join\", \"TMDB + OMDb intersection\", inner_joined.shape)\n",
    "        return inner_joined\n",
    "    \n",
    "    def left_join_integration(self, tmdb_data, external_ratings):\n",
    "        print(\"=== LEFT OUTER JOIN INTEGRATION ===\")\n",
    "        \n",
    "        left_joined = pd.merge(tmdb_data, external_ratings, on='id', how='left')\n",
    "        \n",
    "        external_cols = [col for col in external_ratings.columns if col != 'id']\n",
    "        if external_cols:\n",
    "            null_count = left_joined[external_cols[0]].isnull().sum()\n",
    "        else:\n",
    "            null_count = 0\n",
    "        \n",
    "        print(f\"TMDB data: {len(tmdb_data)} movies\")\n",
    "        print(f\"Left join result: {len(left_joined)} movies\")\n",
    "        print(f\"NULL values introduced: {null_count}\")\n",
    "        \n",
    "        self.log_integration(\"Left Join\", \"TMDB enriched with external ratings\", left_joined.shape)\n",
    "        return left_joined\n",
    "    \n",
    "    def full_outer_join_integration(self, modern_movies, classic_movies):\n",
    "        print(\"=== FULL OUTER JOIN INTEGRATION ===\")\n",
    "        \n",
    "        full_joined = pd.merge(modern_movies, classic_movies, \n",
    "                              on=['title'], how='outer', suffixes=('_modern', '_classic'))\n",
    "        \n",
    "        print(f\"Modern movies: {len(modern_movies)}\")\n",
    "        print(f\"Classic movies: {len(classic_movies)}\")\n",
    "        print(f\"Full join result: {len(full_joined)} movies\")\n",
    "        \n",
    "        self.log_integration(\"Full Outer Join\", \"Complete movie timeline\", full_joined.shape)\n",
    "        return full_joined\n",
    "    \n",
    "    def exclusion_integration(self, movie_data, exclude_years=None):\n",
    "        print(\"=== EXCLUSION INTEGRATION ===\")\n",
    "        \n",
    "        if exclude_years is None:\n",
    "            exclude_years = [2020, 2021]  \n",
    "        \n",
    "        filtered_data = movie_data[~movie_data['release_year'].isin(exclude_years)].copy()\n",
    "        excluded_count = len(movie_data) - len(filtered_data)\n",
    "        \n",
    "        print(f\"Original: {len(movie_data)} movies\")\n",
    "        print(f\"Excluded: {excluded_count} movies\") \n",
    "        print(f\"Clean dataset: {len(filtered_data)} movies\")\n",
    "        \n",
    "        self.log_integration(\"Exclusion\", f\"Removed {exclude_years}\", filtered_data.shape)\n",
    "        return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f612488b",
   "metadata": {},
   "source": [
    "Dataset Versioning System (Applied from Croatia GDP exercise)\n",
    " \n",
    " **Why Dataset Versioning is Critical:**\n",
    " \n",
    " Movie data changes constantly - new releases, updated ratings, box office corrections.\n",
    " \n",
    " Without versioning, you cannot reproduce model results or track which data version\n",
    " \n",
    " produced which predictions. Essential for production ML systems and audit trails.\n",
    "\n",
    "**Real-World Need:** \n",
    "When a model makes wrong predictions, you must trace back to\n",
    "\n",
    "the exact dataset version used for training to debug and improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c44300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetVersionManager:\n",
    "    def create_version_info(self, dataset, integration_log):\n",
    "        timestamp = datetime.now()\n",
    "        dataset_id = f\"MOVIE_SUCCESS_{timestamp.strftime('%Y%m%d_%H%M')}\"\n",
    "        \n",
    "        version_info = {\n",
    "            'dataset_id': dataset_id,\n",
    "            'version': '1.0.0',\n",
    "            'collection_date': timestamp.isoformat(),\n",
    "            'data_sources': {\n",
    "                'tmdb_api': {'movies_collected': len(dataset), 'api_version': 'v3'},\n",
    "                'omdb_api': {'external_data_added': dataset['imdb_rating'].notna().sum()}\n",
    "            },\n",
    "            'integration_techniques': [log['technique'] for log in integration_log],\n",
    "            'quality_filters': ['budget > 0', 'revenue > 0', 'release >= 1990'],\n",
    "            'target_variable': 'success_category (Hit/Break-even/Flop)'\n",
    "        }\n",
    "        \n",
    "        return version_info, dataset_id\n",
    "    \n",
    "    def create_refresh_strategy(self):\n",
    "        \"\"\"Define data update strategy\"\"\"\n",
    "        return {\n",
    "            'tmdb_data': {'frequency': 'Weekly', 'reason': 'New releases'},\n",
    "            'omdb_data': {'frequency': 'Monthly', 'reason': 'Rating updates'}\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb3158d",
   "metadata": {},
   "source": [
    "Main Data Collection Collector Combined\n",
    "\n",
    "\n",
    "This class coordinates all collection components to create the complete movie dataset\n",
    "\n",
    "Combines discovery, detailed extraction, credits, and quality control in systematic workflow\n",
    "\n",
    "Provides progress tracking and error recovery for large-scale data collection\n",
    "\n",
    "Creates the foundational dataset needed for the data provisioning and modeling phases\n",
    "\n",
    "I built this to systematically collect and integrate data from multiple sources while maintaining\n",
    "the original TMDB workflow and adding external validation layers.\n",
    "\n",
    "This creates production-ready datasets with comprehensive quality metrics\n",
    "and progress tracking for large-scale data collection operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataCollector:\n",
    "    def __init__(self, tmdb_key, omdb_key=None):\n",
    "        self.api_handler = APIHandler(tmdb_key, omdb_key)\n",
    "        self.discovery = MovieDiscovery(self.api_handler)  \n",
    "        self.details_extractor = MovieDetailsExtractor(self.api_handler)  \n",
    "        self.credits_extractor = CreditsExtractor(self.api_handler)  \n",
    "        self.success_classifier = SuccessClassifier()  \n",
    "        self.data_checker = DataQualityChecker()  \n",
    "        self.csv_exporter = CSVExporter()  \n",
    "        \n",
    "    def collect_movie_data(self, target_movies=5000, save_progress=True, include_omdb=True):\n",
    "        print(\"Starting movie data collection...\")\n",
    "        \n",
    "        pages_needed = max(1, target_movies // 20)\n",
    "        discovered_movies = self.discovery.discover_movies(pages_needed)  \n",
    "        \n",
    "        complete_movies = []\n",
    "        \n",
    "        for i, movie in enumerate(discovered_movies):\n",
    "            if i >= target_movies:\n",
    "                break\n",
    "                \n",
    "            movie_id = movie['id']\n",
    "            title = movie.get('title')\n",
    "            release_date = movie.get('release_date', '')\n",
    "            year = release_date[:4] if release_date and len(release_date) >= 4 else None\n",
    "            \n",
    "            print(f\"Processing {i+1}/{min(target_movies, len(discovered_movies))}: {title}\")\n",
    "            \n",
    "            movie_details = self.details_extractor.get_movie_details(movie_id, title, year, include_omdb=include_omdb)\n",
    "            if not movie_details:\n",
    "                continue\n",
    "\n",
    "            credits = self.credits_extractor.get_movie_credits(movie_id)\n",
    "            \n",
    "            complete_movie = {**movie_details, **credits}\n",
    "            complete_movie = self.success_classifier.add_useful_features(complete_movie)\n",
    "            \n",
    "            if self.data_checker.is_good_movie_data(complete_movie):\n",
    "                complete_movie = self.data_checker.clean_movie_data(complete_movie)\n",
    "                complete_movies.append(complete_movie)\n",
    "        \n",
    "        filename, df = self.csv_exporter.save_to_csv(complete_movies)\n",
    "        \n",
    "        return filename, df, complete_movies\n",
    "    \n",
    "    def collect_in_batches(self, total_target=10000, batch_size=2500, start_batch=1, include_omdb=True):\n",
    "        print(f\"Starting batch collection: {total_target} total movies in batches of {batch_size}\")\n",
    "        \n",
    "        all_movies = []\n",
    "        batch_files = []\n",
    "        \n",
    "        num_batches = (total_target + batch_size - 1) // batch_size  \n",
    "        pages_per_batch = max(1, batch_size // 20)  \n",
    "        \n",
    "        for batch_num in range(start_batch, num_batches + 1):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"BATCH {batch_num}/{num_batches}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            start_page = (batch_num - 1) * pages_per_batch + 1\n",
    "            end_page = start_page + pages_per_batch - 1\n",
    "            print(f\"Fetching from TMDB pages {start_page} to {end_page}\")\n",
    "            \n",
    "            discovered_movies = self.discovery.discover_movies(\n",
    "                pages=pages_per_batch, \n",
    "                start_page=start_page\n",
    "            )\n",
    "            \n",
    "            complete_movies = []\n",
    "            processed_count = 0\n",
    "            \n",
    "            for i, movie in enumerate(discovered_movies):\n",
    "                if len(complete_movies) >= batch_size:  \n",
    "                    break\n",
    "                    \n",
    "                movie_id = movie['id']\n",
    "                title = movie.get('title')\n",
    "                release_date = movie.get('release_date', '')\n",
    "                year = release_date[:4] if release_date and len(release_date) >= 4 else None\n",
    "                \n",
    "                processed_count += 1\n",
    "                print(f\"Processing {processed_count}/{len(discovered_movies)} (Batch {batch_num}): {title}\")\n",
    "                \n",
    "                movie_details = self.details_extractor.get_movie_details(movie_id, title, year, include_omdb=include_omdb)\n",
    "                if not movie_details:\n",
    "                    continue\n",
    "\n",
    "                credits = self.credits_extractor.get_movie_credits(movie_id)\n",
    "                \n",
    "                complete_movie = {**movie_details, **credits}\n",
    "                complete_movie = self.success_classifier.add_useful_features(complete_movie)\n",
    "                \n",
    "                if self.data_checker.is_good_movie_data(complete_movie):\n",
    "                    complete_movie = self.data_checker.clean_movie_data(complete_movie)\n",
    "                    complete_movies.append(complete_movie)\n",
    "            \n",
    "            batch_df = pd.DataFrame(complete_movies)\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            batch_specific_name = f\"movie_batch_{batch_num}_of_{num_batches}_{timestamp}.csv\"\n",
    "            \n",
    "            list_columns = ['genres', 'production_companies', 'main_cast', 'main_cast_ids']\n",
    "            for col in list_columns:\n",
    "                if col in batch_df.columns:\n",
    "                    batch_df[col] = batch_df[col].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else x)\n",
    "            \n",
    "            batch_df.to_csv(batch_specific_name, index=False)\n",
    "            \n",
    "            print(f\"Batch {batch_num} saved as: {batch_specific_name}\")\n",
    "            print(f\"Batch {batch_num} collected: {len(complete_movies)} valid movies\")\n",
    "            print(f\"Batch {batch_num} processed: {processed_count} total movies\")\n",
    "            \n",
    "            all_movies.extend(complete_movies)\n",
    "            batch_files.append(batch_specific_name)\n",
    "            \n",
    "            if len(all_movies) >= total_target:\n",
    "                print(f\"Reached target of {total_target} movies. Stopping collection.\")\n",
    "                break\n",
    "        \n",
    "        return self._combine_batches(batch_files, all_movies)\n",
    "\n",
    "    def collect_separated_datasets(self, total_target=5000, batch_size=2500):\n",
    "        print(\"=== COLLECTING SEPARATED DATASETS FOR INTEGRATION ===\")\n",
    "        \n",
    "        # Step 1: Collect TMDB-only dataset\n",
    "        print(\"\\n1. Collecting TMDB-only dataset...\")\n",
    "        tmdb_filename, tmdb_df, tmdb_movies = self.collect_in_batches(\n",
    "            total_target=total_target, \n",
    "            batch_size=batch_size, \n",
    "            include_omdb=False\n",
    "        )\n",
    "        \n",
    "        # Step 2: Create OMDb dataset for the same movies\n",
    "        print(\"\\n2. Collecting OMDb data for the same movies...\")\n",
    "        omdb_data = []\n",
    "        \n",
    "        for i, movie in enumerate(tmdb_movies): \n",
    "            title = movie.get('title')\n",
    "            release_date = movie.get('release_date', '')\n",
    "            year = release_date[:4] if release_date and len(release_date) >= 4 else None\n",
    "            movie_id = movie.get('id')\n",
    "            \n",
    "            if title and year and movie_id:\n",
    "                print(f\"Getting OMDb data {i+1}/{len(tmdb_movies)}: {title}\")\n",
    "                external_data = self.api_handler.get_omdb_data(title, str(year))\n",
    "                \n",
    "                if external_data and any(external_data.values()):  # Has meaningful data\n",
    "                    omdb_record = {'id': movie_id, **external_data}\n",
    "                    omdb_data.append(omdb_record)\n",
    "        \n",
    "        omdb_df = pd.DataFrame(omdb_data)\n",
    "        \n",
    "        # Save OMDb dataset\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        omdb_filename = f\"omdb_dataset_{len(omdb_df)}_movies_{timestamp}.csv\"\n",
    "        omdb_df.to_csv(omdb_filename, index=False)\n",
    "        \n",
    "        print(f\"\\nSeparated datasets created:\")\n",
    "        print(f\"TMDB dataset: {tmdb_filename} ({len(tmdb_df)} movies)\")\n",
    "        print(f\"OMDb dataset: {omdb_filename} ({len(omdb_df)} movies)\")\n",
    "        \n",
    "        return tmdb_df, omdb_df\n",
    "\n",
    "    def _combine_batches(self, batch_files, all_movies):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(\"COMBINING BATCHES\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        final_df = pd.DataFrame(all_movies)\n",
    "        \n",
    "        initial_count = len(final_df)\n",
    "        final_df = final_df.drop_duplicates(subset=['id'], keep='first')\n",
    "        final_count = len(final_df)\n",
    "        \n",
    "        print(f\"Total movies collected: {initial_count}\")\n",
    "        print(f\"After removing duplicates: {final_count}\")\n",
    "        print(f\"Duplicates removed: {initial_count - final_count}\")\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        final_filename = f\"movie_dataset_COMPLETE_{final_count}_movies_{timestamp}.csv\"\n",
    "        final_df.to_csv(final_filename, index=False)\n",
    "        \n",
    "        print(f\"Final dataset saved: {final_filename}\")\n",
    "        print(f\"Batch files created: {batch_files}\")\n",
    "        \n",
    "        return final_filename, final_df, all_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fe14e4",
   "metadata": {},
   "source": [
    "Execute Data Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19cba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MOVIE DATA COLLECTION WITH MEANINGFUL INTEGRATION\")\n",
    "print(\"=\" * 60)\n",
    "collector = MovieDataCollector(API_KEY, API_KEY_OMDB)\n",
    "print(\"Collecting separated datasets for integration demonstration...\")\n",
    "tmdb_df, omdb_df = collector.collect_separated_datasets(\n",
    "    total_target=5000, \n",
    "    batch_size=2500\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset Collection Complete!\")\n",
    "print(f\"TMDB dataset: {len(tmdb_df)} movies\")\n",
    "print(f\"OMDb dataset: {len(omdb_df)} movies\")\n",
    "\n",
    "integrator = MovieDataIntegrator()\n",
    "\n",
    "print(f\"\\nDemonstrating Meaningful Integration Techniques:\")\n",
    "\n",
    "# 1. Union: Combine different batches (meaningful)\n",
    "mid = len(tmdb_df) // 2\n",
    "batch1 = tmdb_df.iloc[:mid].copy()\n",
    "batch2 = tmdb_df.iloc[mid:].copy()\n",
    "union_result = integrator.union_integration(batch1, batch2)\n",
    "\n",
    "# 2. Inner Join: Only movies with both TMDB AND OMDb data (meaningful)\n",
    "inner_result = integrator.inner_join_integration(tmdb_df, omdb_df)\n",
    "\n",
    "# 3. Left Join: All TMDB movies + OMDb data where available (meaningful)\n",
    "left_result = integrator.left_join_integration(tmdb_df, omdb_df)\n",
    "\n",
    "# 4. Exclusion: Remove pandemic years (meaningful)\n",
    "clean_result = integrator.exclusion_integration(union_result)\n",
    "\n",
    "print(f\"\\nIntegration Results:\")\n",
    "print(f\"TMDB only: {len(tmdb_df)} movies\")\n",
    "print(f\"OMDb enrichment: {len(omdb_df)} movies\") \n",
    "print(f\"Union (combined batches): {len(union_result)} movies\")\n",
    "print(f\"Inner join (complete data): {len(inner_result)} movies\")\n",
    "print(f\"Left join (TMDB + available OMDb): {len(left_result)} movies\")\n",
    "print(f\"Clean dataset (no pandemic years): {len(clean_result)} movies\")\n",
    "\n",
    "final_analysis_dataset = left_result\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_filename = f\"movie_dataset_INTEGRATED_{len(final_analysis_dataset)}_movies_{timestamp}.csv\"\n",
    "final_analysis_dataset.to_csv(final_filename, index=False)\n",
    "\n",
    "print(f\"\\nIntegration Insights:\")\n",
    "print(f\"• Union combines data collection batches while removing duplicates\")\n",
    "print(f\"• Inner join creates high-quality subset ({len(inner_result)} movies with complete validation)\")\n",
    "print(f\"• Left join preserves all movies while adding external validation where possible\")\n",
    "print(f\"• Exclusion removes {len(union_result) - len(clean_result)} pandemic-affected movies\")\n",
    "\n",
    "print(f\"\\nFinal dataset saved: {final_filename}\")\n",
    "print(f\"Ready for Data Provisioning analysis!\")\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad58b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create simple data dictionary table\n",
    "data = [\n",
    "    ['id', 'Integer', 'Primary key for joins', 'Unique identifier for data integration', 'TMDB API'],\n",
    "    ['title', 'String', 'Not used in ML (text processing complex)', 'Movie identification and validation', 'TMDB API'],\n",
    "    ['budget', 'Integer', 'Core predictor - Higher budgets often mean higher marketing spend, star power', 'Essential for ROI calculation and success threshold', 'TMDB API'],\n",
    "    ['revenue', 'Integer', 'Target variable calculation - Used to create Hit/Break-even/Flop labels', 'Box office performance is ultimate success measure', 'TMDB API'],\n",
    "    ['runtime', 'Integer', 'Predictor - Affects theater scheduling, audience engagement patterns', 'Longer movies = fewer showings per day = potential revenue impact', 'TMDB API'],\n",
    "    ['release_year', 'Integer', 'Predictor - Market conditions, competition levels vary by year', 'Different years have different box office environments', 'TMDB API (derived)'],\n",
    "    ['release_month', 'Integer', 'Strong predictor - Summer/holiday releases perform differently', 'Strategic release timing affects box office potential', 'TMDB API (derived)'],\n",
    "    ['is_summer_movie', 'Boolean', 'Categorical predictor - Summer blockbuster strategy', 'Summer movies target different audiences, higher revenue potential', 'TMDB API (derived)'],\n",
    "    ['is_holiday_movie', 'Boolean', 'Categorical predictor - Holiday release strategy', 'November-December releases target awards season and family audiences', 'TMDB API (derived)'],\n",
    "    ['vote_average', 'Float', 'Predictor - Audience reception affects word-of-mouth marketing', 'Positive reception drives sustained box office performance', 'TMDB API'],\n",
    "    ['vote_count', 'Integer', 'Confidence measure - Sample size for rating reliability', 'More votes = more reliable audience sentiment measure', 'TMDB API'],\n",
    "    ['primary_genre', 'String', 'Categorical predictor - Genre popularity varies by market conditions', 'Different genres have different success patterns and audience sizes', 'TMDB API'],\n",
    "    ['genre_count', 'Integer', 'Predictor - Multi-genre movies target broader audiences', 'More genres might indicate broader appeal or confused marketing', 'TMDB API (calculated)'],\n",
    "    ['director', 'String', 'High-impact predictor - Director track record strongly correlates with success', 'Proven directors reduce investment risk, established fan bases', 'TMDB API'],\n",
    "    ['lead_actor', 'String', 'Star power predictor - A-list actors drive opening weekend performance', 'Star recognition affects marketing effectiveness and audience draw', 'TMDB API'],\n",
    "    ['main_production_company', 'String', 'Predictor - Studio resources and distribution networks vary', 'Major studios have better marketing budgets and theater access', 'TMDB API'],\n",
    "    ['is_us_movie', 'Boolean', 'Market predictor - US movies have different success patterns', 'US films have domestic market advantage and global distribution', 'TMDB API (calculated)'],\n",
    "    ['imdb_rating', 'Float', 'External validation - Independent rating source for model validation', 'IMDb ratings provide second opinion on movie quality', 'OMDb API'],\n",
    "    ['rotten_tomatoes_score', 'Integer', 'Professional critics predictor - Critical acclaim affects awards and longevity', 'Critics scores influence awards season and long-term revenue', 'OMDb API'],\n",
    "    ['metacritic_score', 'Integer', 'Aggregated critics predictor - Professional review consensus', 'Metacritic aggregates multiple professional reviews for balanced view', 'OMDb API'],\n",
    "    ['has_awards', 'Boolean', 'Prestige predictor - Awards recognition drives additional revenue streams', 'Awards boost home video sales, streaming rights, international sales', 'OMDb API (calculated)'],\n",
    "    ['has_oscar_mention', 'Boolean', 'Premium predictor - Oscar recognition significantly affects profitability', 'Oscar nominations/wins create long-term revenue opportunities', 'OMDb API (calculated)'],\n",
    "    ['budget_category', 'String', 'Budget tier predictor - Different budget levels have different success patterns', 'Blockbusters vs indies have different risk/reward profiles', 'TMDB API (calculated)'],\n",
    "    ['profit_ratio', 'Float', 'Target variable - Continuous measure of financial performance', 'Revenue/budget ratio determines investment success', 'Both APIs (calculated)'],\n",
    "    ['success_category', 'String', 'ML Target - Hit/Break-even/Flop classification for supervised learning', 'Industry-standard profitability categories for investment decisions', 'Both APIs (calculated)']\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Field Name', 'Data Type', 'ML Purpose', 'Business Rationale', 'Data Source'])\n",
    "print(\"Data Dictionary\")\n",
    "print(\"=\" * 50)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
