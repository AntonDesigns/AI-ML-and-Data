{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition with a Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qin Zhao PhD & Bas Michielsen MSc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face recognition is the ability for the computer to identify a person based on an image of their face. This is a classification problem, where each possible person is a class, and the provided image should lead to 1 specific class with a as high as feasible certainty. In order to train a classification model with this, we need as many as possible images of the same person's face. In this exercise we use a dataset that is provided by sklearn called the 'Olivetti Faces'. Mote information can be found at https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_olivetti_faces.html\n",
    "\n",
    "The dataset has 400 images for 40 different persons, namely exactly 10 images per person. The dataset is also labelled, so for every image we know the correct class. Now we can use this dataset to train a model.\n",
    "\n",
    "We start by importing scikit-learn, numpy, matplotlib and seaborn the Python libraries we will be using for this analysis. \n",
    "\n",
    "First, we show the versions of these libraries (that is always wise to do in case you have to report problems running the notebooks!) and use the inline plotting mode statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "print('scikit-learn version:', sk.__version__)\n",
    "print('numpy version:', np.__version__)\n",
    "print('matplotlib version:', matplotlib.__version__)\n",
    "print('seaborn version:', sns.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let us load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "faces = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an impression of the data, here we show the first photo of each of the 40 unique people in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subplots = plt.subplots(nrows=4, ncols=10, figsize=(18, 9))\n",
    "subplots = subplots.flatten()\n",
    "    \n",
    "for id in np.unique(faces.target):\n",
    "    index = id *10 # Because there are 10 images per person.\n",
    "    subplots[id].imshow(faces.images[index], cmap=\"gray\")\n",
    "    subplots[id].set_xticks([])\n",
    "    subplots[id].set_yticks([])\n",
    "    subplots[id].set_title(\"id: {}\".format(id))\n",
    "plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Given that we are using images, there is no such thing as feature selection because you cannot select some pixels to be better indicators than other pixels. We therefore have little to do in terms of preprocessing other than splitting the dataset into a trainset and testset.\n",
    "We select a stratisfied test size of .3, which means that from every person 30% of the images will be used as testset. Since every person has 10 images, 7 will be selected for training and 3 will be selected for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(faces.data, faces.target, test_size=.3, random_state=0, stratify=faces.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "In this step we are going to use the trainset only to fit the model. In this case a Support Vector Machine for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # SVC is for classification, an SVR for regression exists as well.\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we can let the model do predictions on the testset and see the accuracy of those predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of a little more than 88% is not too bad. In fact this is quite good. ðŸ˜Š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Now let us see if we can shed some light on the results. The first thing we can do here is print a classification report. This shows for every one of the classes how well the model performed. There are 2 metrics to consider, namely Precision and Recall. The F1-score is a quality score based on precision and recall together.\n",
    "\n",
    "Precision: When the model predicts class X, how often was it correct?\n",
    "\n",
    "Recall: When the correct class is X, how often did the model predict it so?\n",
    "\n",
    "Note that both Precision and Recall are fractions, so 1.00 is 100% of the times, and 0.00 is 0% of the times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that class 39 has a fairly low Precision, this means that often the model says 39 when in fact it is another person. In other words, quite a number of people get identified as person 39 incorrectly. Also it appears that the classes 0, 25 and 34 have a low Recall, this means that these people often get identified as some else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we can do here is making a confusion matrix. This matrix shows all 40 ids (0 - 39) as rows and on every row shows the made predictions for that id in the testset. If the prediction is correct if will show in the [id, id] cell, if not, it will show in another cell and we can see the id that the model predicted instead. Since the testset is stratisfied at 3 images per person, 3 is the maximum of correct classifications, so that should be the vmax parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test, pred)\n",
    "plt.figure(figsize=(15, 15)) # A size of 15 because it feels good! You can try other numbers if you want.\n",
    "sns.heatmap(matrix, annot=True, cbar=None, vmax=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course here we see a similar result as the classification report. In the vast majority of cases the model identifies all 3 images of the same person correctly. However, the column 39 shows many 1s for other rows than 39, and the rows 0, 25 and 34 show many 1s in columns other than the correct one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I use cross_val_score because it automatically performs k-fold cross validation\n",
    "- Reference: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "- I set cv=5 because the exercise asks for 5-fold cross validation\n",
    "- I apply this on X_train and y_train because I want to validate the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "# I print each score because the exercise asks to show what the accuracy scores are\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "# I calculate the mean because the exercise asks for the average accuracy score\n",
    "print(\"Average accuracy:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I import StratifiedKFold because the exercise specifically asks to use this function\n",
    "- Reference: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "- I use n_splits=5 because the exercise asks for k=5\n",
    "- I set shuffle=True and random_state=0 to ensure reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "accuracies = []\n",
    "\n",
    "# I loop through the folds because I need to manually train and test on each fold\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    # I split the data using the indices because StratifiedKFold gives me train/val indices\n",
    "    X_fold_train = X_train[train_index]\n",
    "    X_fold_val = X_train[val_index]\n",
    "    y_fold_train = y_train[train_index]\n",
    "    y_fold_val = y_train[val_index]\n",
    "    \n",
    "    # I create a new model for each fold because each fold needs its own trained model\n",
    "    fold_model = SVC()\n",
    "    fold_model.fit(X_fold_train, y_fold_train)\n",
    "    \n",
    "    # I predict on the validation set because I need to evaluate this fold's performance\n",
    "    fold_pred = fold_model.predict(X_fold_val)\n",
    "    # I calculate accuracy because the exercise asks for accuracy score of each fold\n",
    "    fold_acc = accuracy_score(y_fold_val, fold_pred)\n",
    "    # I append to the list because I need to calculate the average later\n",
    "    accuracies.append(fold_acc)\n",
    "    \n",
    "    # I print each fold's accuracy because I need to print out the accuracy score of each fold\n",
    "    print(\"Fold\", fold+1, \"accuracy:\", fold_acc)\n",
    "\n",
    "# I calculate the mean because I need to calculate the average accuracy score\n",
    "print(\"Average accuracy:\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glasses Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I will solve a binary classification problem because the exercise asks to detect glasses instead of recognizing people\n",
    "- Reference for binary classification with SVM: https://scikit-learn.org/stable/modules/svm.html#classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create the glasses_ranges list\n",
    "glasses_ranges = [\n",
    "    (10, 19), (30, 32), (37, 38), (50, 59), (63, 64),\n",
    "    (69, 69), (120, 121), (124, 129), (130, 139), (160, 161),\n",
    "    (164, 169), (180, 182), (185, 185), (189, 189), (190, 192),\n",
    "    (194, 194), (196, 199), (260, 269), (270, 279), (300, 309),\n",
    "    (330, 339), (358, 359), (360, 369)\n",
    "]\n",
    "\n",
    "# I create a target array of all zeros because initially no one has glasses (0 = no glasses)\n",
    "glasses = np.zeros(len(faces.data))\n",
    "\n",
    "# I loop through the ranges because I need to mark all images with glasses as 1\n",
    "for start, end in glasses_ranges:\n",
    "    # I set indices from start to end+1 because Python ranges are exclusive at the end\n",
    "    # I use end+1 because the exercise says \"up to and including\" the end index\n",
    "    glasses[start:end+1] = 1\n",
    "\n",
    "# I print these statistics because I want to verify the target variable was created correctly\n",
    "print(\"Total images with glasses:\", np.sum(glasses))\n",
    "print(\"Total images without glasses:\", len(glasses) - np.sum(glasses))\n",
    "\n",
    "# I split the data because the exercise asks to create a training & test set for this new problem\n",
    "# I use stratify=glasses because I want both sets to have similar proportions of glasses/no glasses\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "    faces.data, glasses, test_size=.3, random_state=0, stratify=glasses\n",
    ")\n",
    "\n",
    "# I train a new SVM model I need to train support vector machine for the new target\n",
    "model_glasses = SVC()\n",
    "model_glasses.fit(X_train_g, y_train_g)\n",
    "\n",
    "# I predict on the test set because I need to evaluate the model's performance\n",
    "pred_glasses = model_glasses.predict(X_test_g)\n",
    "acc_glasses = accuracy_score(pred_glasses, y_test_g)\n",
    "print(\"Glasses classification accuracy:\", acc_glasses)\n",
    "\n",
    "# I show the classification report because the exercise asks to show a classification report\n",
    "print(classification_report(y_test_g, pred_glasses, target_names=['No Glasses', 'Glasses']))\n",
    "\n",
    "# I apply cross validation because the exercise asks to apply cross validation to avoid overfitting\n",
    "cv_scores_glasses = cross_val_score(model_glasses, X_train_g, y_train_g, cv=5)\n",
    "print(\"Cross-validation scores:\", cv_scores_glasses)\n",
    "print(\"Average accuracy:\", cv_scores_glasses.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "43ddb32909a53c204e37ff1af9486355a00187ad4c4605503a535aa055c1095c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
